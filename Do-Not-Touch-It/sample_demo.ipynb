{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad7d20f-1508-466d-ae9d-ee374d679af4",
   "metadata": {},
   "source": [
    "# 0.准备\n",
    "本地安装huggingface embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6673952-3ea7-4edd-bc68-31ab06239e51",
   "metadata": {},
   "source": [
    "1.在VS-code虚拟环境的目录中，pip会优先读取pip.ini（Windows）配置文件。这些文件的默认路径是：\n",
    "myenv\\pip.ini\n",
    "\n",
    "2.在对应文件中添加以下内容：\n",
    "Windows (pip.ini)\n",
    "路径：myenv\\pip.ini\n",
    "内容：\n",
    "ini\n",
    "[global]\n",
    "index-url = https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "3.激活虚拟环境后，安装任意包并验证是否使用清华源：\n",
    "pip install <package-name>\n",
    "如果设置成功，安装过程中你会看到类似以下输出：\n",
    "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c5607-3618-44c6-8f1c-a868090a5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0824b-e483-4781-a028-2bd28645a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b648933-06a2-4702-9c66-7f4745b31985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a8f95-f890-4e4a-9740-86c2257e7700",
   "metadata": {},
   "source": [
    "# 1.模块导入：openai等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fdca3e-c32e-4acf-a702-fb6fb3640b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# import os\n",
    "# key=os.getenv(\"LangGraph——OPEN AI KEY\")\n",
    "\n",
    "# api_key = str(key)\n",
    "# api_url = \"https://api.zetatechs.com/v1\"\n",
    "# client = OpenAI(base_url=api_url, api_key=api_key)\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(model=\"gpt-4\",base_url=api_url, api_key=api_key,temperature=0)\n",
    "\n",
    "import os\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=\"ChatGLM_API_KEY\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4cd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1643f4-23c4-4b50-95b8-b5733668ff4c",
   "metadata": {},
   "source": [
    "# 2.加载文本文件并将向量数据库保存到本地\n",
    "文档加载方法n\n",
    "from langchain.document_loaders import TextLoader\n",
    "#加载本地文本文件\n",
    "loader = TextLoader(\"path/to/your/file.txt\")\n",
    "documents = loader.lad()\n",
    "\n",
    "加载 PDF 文件python\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "#加载本地 PDF 文件\n",
    "loader = PyPDFLoader(\"path/to/your/file.pdf\")\n",
    "documents = loder.load()\n",
    "\n",
    "加载 Word 文件python\n",
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "#加载本地 Word 文件\n",
    "loader = UnstructuredWordDocumentLoader(\"path/to/your/file.docx\")\n",
    "document = loader.load()\n",
    "\n",
    "加载 Excel 文件python\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "#加载本地 Excel 文件\n",
    "loader = UnstructuredExcelLoader(\"path/to/your/file.xlsx\")\n",
    "do\n",
    "# 3.调用本地的HuggingFaceEmbedding  Model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" # 你可以选择其他支持的模型名称\n",
    "local_embeddings = HuggingFaceEmbeddings(model_name=model_name)cuments = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1c8c28-3f3b-484c-9604-72b6c5cf2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#加载 PDF 文件调用工具P\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c214e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "D:\\Computer\\ipykernel_25804\\2129114092.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  loader = PyPDFLoader(\"D:\\pythonProject\\Linear Algebra and Learning from Data (Gilbert Strang) (Z-Library).pdf\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载本地 PDF 文件\n",
    "loader = PyPDFLoader(\"D:\\pythonProject\\Linear Algebra and Learning from Data (Gilbert Strang) (Z-Library).pdf\")\n",
    "documents1 = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c427254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 合并文档列表\n",
    "all_documents = documents1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5744b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 初级文档分割策略拆分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "#all_splits 包含了文件分割后的所有文档\n",
    "all_splits = text_splitter.split_documents(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82d68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2692cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\",\n",
    "    openai_api_key=\"ChatGLM_API_KEY\",\n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6dddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer\\ipykernel_25804\\3409896792.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "d:\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf224893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer\\ipykernel_25804\\1604825996.py:13: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()  # 保存数据库到本地\n"
     ]
    }
   ],
   "source": [
    "# # 准备 Hugging Face 嵌入模型\n",
    "# model_name = \"sentence-transformers/all-MiniLM-L6-v2\" # 你可以选择其他支持的模型名称\n",
    "# local_embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# 将文档转换为 Chroma 向量存储\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./VectorStore/\"\n",
    ")\n",
    "vectorstore.persist()  # 保存数据库到本地"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5c4ab-96e8-427f-ba7e-50bd615287a2",
   "metadata": {},
   "source": [
    "# 4.链式调用与实践\n",
    "由于嵌入模型与向量数据库维数的关系，question的嵌入模型与本地向量数据库所使用的嵌入模型务必保持一致；\n",
    "此外，生成查询的嵌入将会转换为列表；\n",
    "最后，此处由于使用HuggingFaceEmbeddings Model需将将嵌入函数改为直接计算嵌入，返回列表形式的嵌入，进而调用本地向量数据库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1cee62-ded6-4d50-b81c-bba5e217fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 使用 sentence-transformers 加载模型\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 将嵌入函数改为直接计算嵌入\n",
    "def embedding_function(text):\n",
    "    return model.encode([text])[0].tolist()  # 返回列表形式的嵌入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29b47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer\\ipykernel_25804\\1657562213.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载 Chroma 向量数据库\n",
    "\n",
    "question = \"What's the author of this book? Introduce him/her. \"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./chroma-storage/\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "question_embedding = embedding_function(question)  # 生成查询的嵌入并转换为列表\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6db7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#使用本地模型和向量存储执行问答。下面是一个带有简单字符串提示符的示例\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "#使用RunnablePassthrough进行检索\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "您是问答任务的助理。使用以下检索到的上下文来回答问题。如果你不知道答案，就说你不知道。保持答案详细，概要。\n",
    "回答以英文和中文双版本！！！！\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdec9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be51871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.string import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b838e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=lambda input: format_docs(input[\"context\"]))\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 使用向量搜索\n",
    "docs = vectorstore.similarity_search_by_vector(question_embedding)  # 传递单一嵌入向量\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\": docs, \"question\": question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
